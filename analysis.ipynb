{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weather Prediction Model\n",
    "#### Mini Project\n",
    "\n",
    "###### by Matthew Parker\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project, data of past weather for three cities - Bristol, Reykjavik, and Los Angeles - is provided. This is used to predict upcoming weather in all three of these cities, using Monte Carlo Markov Chains. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports used throughout this project\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from assessment_4_imports import merge_specific_data, get_unique_conds, calc_discrete_probability_array, plot_probabilities, assign_colours\n",
    "from assessment_4_imports import multiple_data_predictions, plot_predictions, compare_variations, calc_cont_prob_arrays\n",
    "from matplotlib import colormaps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of cities for which data is provided\n",
    "# Number of cities can be changed and the whole code will still run (as long there is csv data for any cities added).\n",
    "\n",
    "cities = ['bristol', 'reykjavik', 'la']\n",
    "num_cities = len(cities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make dictionary of the city names and the data provided\n",
    "\n",
    "all_data = {}\n",
    "\n",
    "for city in cities:\n",
    "    all_data[city] = pd.read_csv(f'datasets/{city}_weather_winter.csv')\n",
    "\n",
    "# A sample of one of the dataframes to show how the data is provided. \n",
    "# Only the first 3 rows of 2760 are shown.\n",
    "all_data['bristol'].head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the summary columns for each city into one dataset\n",
    "\n",
    "summary_merged =  merge_specific_data(all_data, 'summary')\n",
    "summary_merged.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all the unique conditions that occur across all the datasets for the summary data\n",
    "unsorted_unique_conditions = get_unique_conds(summary_merged)\n",
    "\n",
    "(unsorted_unique_conditions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the unique conditions into an order that makes more sense (increasing extremity of weather)\n",
    "unique_weather_conditions = []\n",
    "\n",
    "display_order= [3,2,1,0,4]\n",
    "for i in display_order:\n",
    "    unique_weather_conditions.append(unsorted_unique_conditions[i])\n",
    "\n",
    "print(unique_weather_conditions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate probability array of the next weather conditions for bristol as an example. \n",
    "# The values give the probability that the column condition will occur, given that the last condition was the row condition\n",
    "\n",
    "probability_array, probability_df = calc_discrete_probability_array(summary_merged['bristol'], unique_weather_conditions)\n",
    "probability_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary containing the probability arrays for each city\n",
    "\n",
    "# Empty dictionary\n",
    "summary_prob_arrays = {}\n",
    "\n",
    "# Constrained layout used to make figure look better with the inclusion of a colour bar.\n",
    "fig, axes = plt.subplots(ncols=num_cities, figsize=(20,6), layout='constrained')\n",
    "\n",
    "# Used to determine which figure the colourbar should be plotted underneath\n",
    "central_plot = round( (num_cities - 1) / 2 )\n",
    "\n",
    "for i, city in enumerate(cities):\n",
    "    \n",
    "    # Calculate probability array for each city\n",
    "    probability_array = calc_discrete_probability_array(summary_merged[f'{city}'], unique_weather_conditions)[0]\n",
    "    \n",
    "    # Add probability array to dictionary\n",
    "    summary_prob_arrays[city] = probability_array\n",
    "    \n",
    "    ax = axes[i]\n",
    "    \n",
    "    # Add colourbar to central plot \n",
    "    colourbar_bool=False\n",
    "    if i == central_plot:\n",
    "        colourbar_bool = True\n",
    "\n",
    "    plot_probabilities(city_prob_array=probability_array, ax=ax, \n",
    "                       unique_conds=unique_weather_conditions, title=city, colourbar=colourbar_bool)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot of single prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign colours to each unique weather condition\n",
    "\n",
    "# Colours chosen to maximise contrast to make it easier to see the different conditions\n",
    "colours_list = ['lawngreen', 'orangered', 'dimgrey', 'magenta', 'deepskyblue']\n",
    "summary_colours_dict = assign_colours(unique_weather_conditions, colours_list)\n",
    "summary_colours_dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot of a single prediction for each of the three cities\n",
    "\n",
    "fig, axes = plt.subplots(ncols=num_cities, figsize=(23, 5))\n",
    "\n",
    "# Single prediction\n",
    "samples=1\n",
    "num_predictions=100\n",
    "initial_selection='Clear'\n",
    "\n",
    "for i, city in enumerate(cities):\n",
    "\n",
    "    # probability array of the desired city, obtained from the dictionary created earlier\n",
    "    prob_array = summary_prob_arrays[f'{city}']\n",
    "    \n",
    "    # Obtain the prediction of the weather summary data for this specific city.\n",
    "    city_summary_prediction = multiple_data_predictions(prob_array=prob_array, samples=samples, num_predictions=num_predictions,\n",
    "                                                        possible_conditions=unique_weather_conditions, initial_selection=initial_selection)\n",
    "\n",
    "    # Axis for predictions to be plotted on.\n",
    "    ax = axes[i]\n",
    "    \n",
    "    # PLot y_label only on leftmost figure. Other labels overlaps with over figures. \n",
    "    y_label = None\n",
    "    if i==0:\n",
    "        y_label = 'Weather_conditions'\n",
    "    \n",
    "    # Plot the predictions\n",
    "    plot_predictions(city_summary_prediction, colours=summary_colours_dict, axis=ax, title=f'{city}', y_label=y_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In these plots, it can generally be seen that Bristol has more variable weather, Reykjavik is often the only city to have snow conditions, and LA generally has significantly more clear weather than the other cities. \n",
    "\n",
    "However, because the prediction is randomly generated and these plots show only one run, these patterns are not guaranteed to occur. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot multiple sets of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "samples = 20\n",
    "num_predictions = 100\n",
    "initial_selection = 'Clear'\n",
    "\n",
    "# If more than 250 predictions, stack subplots vertically instead of horizontally.\n",
    "# This ensures the scatter plot points touch which I think makes it way easier to visualise changes in weather compared to if they are distinct points. \n",
    "numcols=num_cities\n",
    "numrows=1\n",
    "if num_predictions >= 250:\n",
    "    numcols=1\n",
    "    numrows=num_cities\n",
    "\n",
    "# Extend length of subplots if plots stacked vertically\n",
    "fig, ax = plt.subplots(nrows=numrows, ncols=numcols, figsize=(19, 5*numrows))\n",
    "\n",
    "\n",
    "# Plot predictions for each city\n",
    "for i, city in enumerate(cities):\n",
    "    \n",
    "    # Probability array for this city\n",
    "    prob_array = summary_prob_arrays[f'{city}']\n",
    "\n",
    "    legend_bool=False\n",
    "    \n",
    "    # Plot legend in middle if subplots stacked horizontally\n",
    "    if numrows==1 and i==1:\n",
    "        legend_bool=True\n",
    "    # Plot legend at bottom if subplots stacked vertically\n",
    "    elif numcols==1 and i==2:\n",
    "        legend_bool=True\n",
    "\n",
    "    predictions_list = multiple_data_predictions(prob_array=prob_array, samples=samples, num_predictions=num_predictions,\n",
    "                                                 possible_conditions=unique_weather_conditions, initial_selection=initial_selection)\n",
    "    \n",
    "    plot_predictions(predictions_list, colours=summary_colours_dict, axis=ax[i], plot_legend=legend_bool, y_label='Weather Conditions');\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case it is clearer to see that LA generally remains more clear, Reyjkavik is more likely to have snowy conditions, and Bristol has high variability.\n",
    "\n",
    "**Scalability with large iterations**\n",
    "\n",
    "The model will scale fairly well for large iterations.\n",
    "However, there are some major problems which may come up with predictions with large iterations.\n",
    "For example, this model would not work when attempting to predict conditions for summer, as the data is only provided across the winter months.\n",
    "Also, if the number of iterations were to increase in order to predict multiple weeks rather than a few days, the computational power required would increase signifcantly.  \n",
    "\n",
    "**More states introduced**\n",
    "\n",
    "If more states were introduced, the computational power would also increase, as each probability array would be larger and take significantly longer to calculate.\n",
    "\n",
    "**Other limitations**\n",
    "\n",
    "The model assumes that weather conditions are only dependent on the last state, which means it does not account for weather patterns that occur over multiple hours. However, with a relatively small dataset like the one provided, there is a potential for overfitting if multiple past conditions were used. \n",
    "\n",
    "Furthermore, this model does not use the quantitative data provided. This data could be used to significantly improve the model used, as there are likely relationships between, for example, temperature and the next weather condition. Howver, incorporating this would significantly increase the complexity of the model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variation checker\n",
    "\n",
    "Little function to quantify the average number of switches between different conditions for each city. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_variations(cities, summary_prob_arrays, 20, 100, possible_conditions=unique_weather_conditions, initial_selection='Clear')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bristol has the most variation, with a higher average number of changes between different weather conditions compared to Reykjavik and LA (which has the least). \n",
    "This is expected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------\n",
    "\n",
    "### Continuous data predictions\n",
    "\n",
    "The following section is an initial model that can be used to predict data for any of the continuous numerical data provided. \n",
    "\n",
    "These results are generally not tailored, so the colouring and bins may not be as optimised as the solution above.\n",
    "However, it should work without any errors and produce plausible predictions for the numerical data given. \n",
    "\n",
    "With more time this could've been further refined and potentially reduced into a single function. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Temperature\n",
    "\n",
    "Currently, the data below makes predictions for the temperature data provided in the dataset above. \n",
    "\n",
    "However, there are some major limitations:\n",
    "\n",
    "- First of all, temperature is continuous, whereas the summary data used above was discrete. This adds in the need to split the temperature into bins.\n",
    "- The bins were calculated to have the same number of data across all the cities in each bin. This means the bin sizes are not the same width. For clarity, this does not mean the bins have the same number of data in them for each city, they have an equal number across all the cities. \n",
    "- 10 bins were used - more than the number of unique weather conditions - which means a slightly longer calculation time. However, it all allows more detail in the plots. \n",
    "- It is unknown how the temperature is distributed within a bin: I debated calculating a random temperature within a bin, but this would not be based on any fact and decided to stick to just having the temperatures plotted into their designated bins. This produces a much less realistic graph, as the temperatures would have variation within the bins, but the figures show the rough change in temperature over the course of the predictions for each city.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shows column names and which data is numerical\n",
    "\n",
    "all_data['bristol'].head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Input the name of the column of interest below.**\n",
    "This is initially set to temperature but can take other values such as precipAccumulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input the name of the column of interest here. \n",
    "# If it does not belong in the column names, a ValueError will occur\n",
    "column_of_interest = 'temperature'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge data across the three cities into one dataframe\n",
    "merged =  merge_specific_data(all_data, column_of_interest)\n",
    "\n",
    "# Get unique conditions across the cities  \n",
    "# This is used to calculate the bins across the whole temperature distribution across the three cities. \n",
    "# Reykjavik and LA do not have the same temperature ranges, so this was used to standardise the temperature range across the cities\n",
    "# This means the temperatures in the plots below align across each subplot\n",
    "values_across_cities = get_unique_conds(merged)\n",
    "print((values_across_cities).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get probability arrays, bins, and bin_indices for bristol\n",
    "\n",
    "cont_probability_array, cont_probability_df, bin_indices, bins = calc_cont_prob_arrays(merged['bristol'], values_across_cities )\n",
    "\n",
    "# Labels of the dataframe show the upper bounds of that specific bin\n",
    "cont_probability_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dictionary of temperature probability arrays for each city\n",
    "# PLot each one.\n",
    "\n",
    "# Empty dictionary\n",
    "prob_arrays = {}\n",
    "\n",
    "fig, axes = plt.subplots(ncols=num_cities, figsize=(20,6), layout='constrained')\n",
    "\n",
    "# Used to determine which figure the colourbar should be plotted underneath\n",
    "central_plot = round( (num_cities - 1) / 2 )\n",
    "\n",
    "for i, city in enumerate(cities):\n",
    "    \n",
    "    # Calculate probability array for each city\n",
    "    # probability_array = calc_discrete_probability_array(summary_merged[f'{city}'], unique_weather_conditions)[0]\n",
    "    probability_array = calc_cont_prob_arrays(merged[f'{city}'], values_across_cities )[0]\n",
    "    \n",
    "    # Add probability array to dictionary\n",
    "    prob_arrays[city] = probability_array\n",
    "    \n",
    "    ax = axes[i]\n",
    "    \n",
    "    # Add colourbar to central plot \n",
    "    colourbar_bool=False\n",
    "    if i == central_plot:\n",
    "        colourbar_bool = True\n",
    "\n",
    "    plot_probabilities(city_prob_array=probability_array, ax=ax, \n",
    "                       unique_conds=bins, title=city, colourbar=colourbar_bool)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Colour map from blue to white to red - classic colour distinctions for temperatures\n",
    "# This makes less sense if the colomn_of_interest is not temperature, but still works\n",
    "cmap = colormaps['bwr']\n",
    "\n",
    "# Get colours along regular intervals of colourmap\n",
    "colours = cmap(np.linspace(0, 1, len(bins)))\n",
    "colours_dict = assign_colours(bins, colours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot of single temperature prediction for  each city. \n",
    "samples=1\n",
    "\n",
    "fig, axes = plt.subplots(ncols=num_cities, figsize=(20, 5))\n",
    "\n",
    "# Arbitrary initial selection\n",
    "initial_selection = bins[-5]\n",
    "print(f'Initial selection of continuous bin: {initial_selection}')\n",
    "\n",
    "for i, city in enumerate(cities):\n",
    "    ax = axes[i]\n",
    "    \n",
    "    prob_array = prob_arrays[f'{city}']\n",
    "    \n",
    "    legend_bool=False\n",
    "    \n",
    "    # Plot legend in middle if subplots stacked horizontally\n",
    "    if numrows==1 and i==1:\n",
    "        legend_bool=True\n",
    "    # Plot legend at bottom if subplots stacked vertically\n",
    "    elif numcols==1 and i==2:\n",
    "        legend_bool=True\n",
    "    # city_summary_prediction = data_prediction(prob_array, num_predictions=100, possible_conditions=unique_weather_conditions, initial_selection='Clear')\n",
    "    \n",
    "    city_prediction = multiple_data_predictions(prob_array=prob_array, samples=samples, num_predictions=100, \n",
    "                                                        possible_conditions=bins , initial_selection=initial_selection)\n",
    "    \n",
    "    y_label=None\n",
    "    if i == 0: \n",
    "        y_label='bounds'\n",
    "        \n",
    "    plot_predictions(city_prediction, colours=colours_dict, axis=ax, plot_legend=legend_bool, title=f'{city}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reykjavik generally goes to lower temperatures, whereas La goes to higher temperatures. Bristol is more random.\n",
    "\n",
    "Once again, these patterns may not be seen in these plots directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot of single temperature prediction for  each city. \n",
    "\n",
    "samples=20\n",
    "\n",
    "fig, axes = plt.subplots(ncols=num_cities, figsize=(20, 5))\n",
    "\n",
    "# Arbitrary initial selection\n",
    "initial_selection = bins[-5]\n",
    "print(f'Initial selection of continuous bins: {initial_selection}')\n",
    "\n",
    "for i, city in enumerate(cities):\n",
    "    ax = axes[i]\n",
    "    \n",
    "    prob_array = prob_arrays[f'{city}']\n",
    "    \n",
    "    legend_bool=False\n",
    "    \n",
    "    # Plot legend in middle if subplots stacked horizontally\n",
    "    if numrows==1 and i==1:\n",
    "        legend_bool=True\n",
    "    # Plot legend at bottom if subplots stacked vertically\n",
    "    elif numcols==1 and i==2:\n",
    "        legend_bool=True\n",
    "    # city_summary_prediction = data_prediction(prob_array, num_predictions=100, possible_conditions=unique_weather_conditions, initial_selection='Clear')\n",
    "    \n",
    "    city_prediction = multiple_data_predictions(prob_array=prob_array, samples=samples, num_predictions=100, \n",
    "                                                        possible_conditions=bins , initial_selection=initial_selection)\n",
    "    \n",
    "    y_label=None\n",
    "    if i == 0: \n",
    "        y_label='bounds'\n",
    "        \n",
    "    plot_predictions(city_prediction, colours=colours_dict, axis=ax, plot_legend=legend_bool, title=f'{city}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The general patterns mentioned above can be spotted more easily in this plot. LA generally has much more (dark) red, with low amounts of blue. Reykjavik on the other hand has large expanses of dark blue, signifying the expected colder temperatures. \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
